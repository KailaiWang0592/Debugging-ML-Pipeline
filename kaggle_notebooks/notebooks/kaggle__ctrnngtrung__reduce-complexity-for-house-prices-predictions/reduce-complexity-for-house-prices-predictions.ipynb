{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reduce Complexity & Training Time By Not Using Object Features (28 Features Remaining) For House Predictions**\n",
    "---\n",
    "**1. ANALYZING AND CLEANING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-03T08:13:15.195947Z",
     "iopub.status.busy": "2023-09-03T08:13:15.195504Z",
     "iopub.status.idle": "2023-09-03T08:13:15.208481Z",
     "shell.execute_reply": "2023-09-03T08:13:15.207245Z",
     "shell.execute_reply.started": "2023-09-03T08:13:15.195915Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:14:39.594226Z",
     "iopub.status.busy": "2023-09-03T08:14:39.593724Z",
     "iopub.status.idle": "2023-09-03T08:14:39.632029Z",
     "shell.execute_reply": "2023-09-03T08:14:39.631023Z",
     "shell.execute_reply.started": "2023-09-03T08:14:39.594185Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/share/dutta/eyao/dataset/kaggle/house-prices-advanced-regression-techniques/train.csv') \n",
    "print(\"Table Shape: {}\".format(data.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:13:15.257226Z",
     "iopub.status.busy": "2023-09-03T08:13:15.256763Z",
     "iopub.status.idle": "2023-09-03T08:13:15.286466Z",
     "shell.execute_reply": "2023-09-03T08:13:15.285177Z",
     "shell.execute_reply.started": "2023-09-03T08:13:15.257184Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(7) # See 7 information row at the top of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **missing data** appear in many columns such as: Alley, PoolQC, Fence, MiscFeature,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:14:41.541698Z",
     "iopub.status.busy": "2023-09-03T08:14:41.54122Z",
     "iopub.status.idle": "2023-09-03T08:14:41.576434Z",
     "shell.execute_reply": "2023-09-03T08:14:41.575089Z",
     "shell.execute_reply.started": "2023-09-03T08:14:41.541661Z"
    }
   },
   "outputs": [],
   "source": [
    "null_class = data.isnull().sum() \n",
    "print(null_class[null_class != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:13:15.327315Z",
     "iopub.status.busy": "2023-09-03T08:13:15.326791Z",
     "iopub.status.idle": "2023-09-03T08:13:15.494296Z",
     "shell.execute_reply": "2023-09-03T08:13:15.492617Z",
     "shell.execute_reply.started": "2023-09-03T08:13:15.327266Z"
    }
   },
   "outputs": [],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate each data and how to handle each feature base on above tables\n",
    "\n",
    "1. Alley, PoolQC, Fence, MiscFeature:\n",
    "> * Because the number of missing value is very large => It will adversely affects the regression model. \n",
    "> * Solution: I will remove these features (delete NaN columns).\n",
    "2. MasVnrType, MasVnrArea, Electrical:\n",
    "> * Because the number of missing values is very small => It doesn't affect the model much. \n",
    "> * Solution: I will remove these samples (delete NaN rows).\n",
    "3. BsmtQual, BsmtCond, BsmtExposure,BsmtFinType1, BsmtFinType2, GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond:\n",
    "> * These are basement and garage data and they represent only 2.5% to 5.5% of the total sample.\n",
    "> * Because these are the features chosen according to human behavior. I will replace NaN with the most common value for each feature.\n",
    "4. LotFrontage, FireplaceQu:\n",
    "> Because the missing data of LotFrontage (17.7%) is quite a lot but 25% and 75% stats don't change much. FireplaceQu accounts for almost 50% of all samples.\n",
    "> * Solution: LotFrontage - I'll replace these values with the mean. FireplaceQu - I will remove this feature.\n",
    "5. Object Features.\n",
    "> * Solution: convert feature objects into one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:14:43.718054Z",
     "iopub.status.busy": "2023-09-03T08:14:43.717591Z",
     "iopub.status.idle": "2023-09-03T08:14:43.809221Z",
     "shell.execute_reply": "2023-09-03T08:14:43.807948Z",
     "shell.execute_reply.started": "2023-09-03T08:14:43.718018Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(df, train_data=True):\n",
    "    drop_rows_list = [\"MasVnrType\", \"MasVnrArea\", \"Electrical\"]\n",
    "    if train_data:\n",
    "        # Drop NaN rows\n",
    "        for sample_row in drop_rows_list:\n",
    "            df.drop(df[df[sample_row].isnull()].index, inplace=True)\n",
    "\n",
    "    # Replace NaN with the most common value\n",
    "    most_common_list = [\"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\"BsmtFinType1\", \"BsmtFinType2\", \n",
    "                        \"GarageType\", \"GarageYrBlt\", \"GarageFinish\", \"GarageQual\", \"GarageCond\"]\n",
    "    for sample_row in most_common_list:\n",
    "        df[sample_row].fillna(df[sample_row].mode()[0], inplace=True)\n",
    "\n",
    "    # Replace NaN with Mean  \n",
    "    df.LotFrontage.fillna(df.LotFrontage.mean(), inplace=True)\n",
    "\n",
    "    # Remove some unecessary columns\n",
    "    removed_features_list = [\"Alley\", \"PoolQC\", \"Fence\", \"MiscFeature\", \"FireplaceQu\", \"Id\"]\n",
    "    for feature in removed_features_list:\n",
    "        del df[feature]\n",
    "    \n",
    "    if not train_data:\n",
    "        # Replace NaN with the  most common value for test set \n",
    "        for sample_row in test_set.isnull().columns:\n",
    "            df[sample_row].fillna(df[sample_row].mode()[0], inplace=True)\n",
    "            \n",
    "    return df\n",
    "\n",
    "def preprocess_no_obj_feature(df, train_data=True):\n",
    "    drop_rows_list = [\"MasVnrType\", \"MasVnrArea\", \"Electrical\"]\n",
    "    if train_data:\n",
    "        # Drop NaN rows\n",
    "        for sample_row in drop_rows_list:\n",
    "            df.drop(df[df[sample_row].isnull()].index, inplace=True)\n",
    "\n",
    "    # Replace NaN with the most common value\n",
    "    most_common_list = [\"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\"BsmtFinType1\", \"BsmtFinType2\", \n",
    "                        \"GarageType\", \"GarageYrBlt\", \"GarageFinish\", \"GarageQual\", \"GarageCond\"]\n",
    "    for sample_row in  data.select_dtypes(include=['object']).columns:\n",
    "        df[sample_row].fillna(df[sample_row].mode()[0], inplace=True)\n",
    "\n",
    "    # Replace NaN with Mean  \n",
    "    df.LotFrontage.fillna(df.LotFrontage.mean(), inplace=True)\n",
    "    \n",
    "    # Remove some unecessary columns\n",
    "    removed_features_list = [\"Alley\", \"PoolQC\", \"Fence\", \"MiscFeature\", \"FireplaceQu\", \"Id\"]\n",
    "    for feature in removed_features_list:\n",
    "        del df[feature]\n",
    "        \n",
    "    # Delete all remaining object features\n",
    "    for feature in df.select_dtypes(include=['object']).columns:\n",
    "        del df[feature]\n",
    "    \n",
    "    if not train_data:\n",
    "        # Replace NaN with the  most common value for test set \n",
    "        for sample_row in test_set.isnull().columns:\n",
    "            df[sample_row].fillna(df[sample_row].mode()[0], inplace=True)\n",
    "            \n",
    "    return df\n",
    "\n",
    "# We can choose 1 of 2 preprocess methods.\n",
    "# data = preprocess(data, train_data=True) # This preprocess for using object features\n",
    "data = preprocess_no_obj_feature(data, train_data=True) # Do not use object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:13:15.605814Z",
     "iopub.status.busy": "2023-09-03T08:13:15.605124Z",
     "iopub.status.idle": "2023-09-03T08:13:15.633677Z",
     "shell.execute_reply": "2023-09-03T08:13:15.631899Z",
     "shell.execute_reply.started": "2023-09-03T08:13:15.605764Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**2. EXAMINING AND EXPLORING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:14:47.005551Z",
     "iopub.status.busy": "2023-09-03T08:14:47.005014Z",
     "iopub.status.idle": "2023-09-03T08:14:47.081029Z",
     "shell.execute_reply": "2023-09-03T08:14:47.079383Z",
     "shell.execute_reply.started": "2023-09-03T08:14:47.005509Z"
    }
   },
   "outputs": [],
   "source": [
    "correlation_matrix = pd.DataFrame.corr(data) \n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:14:49.842622Z",
     "iopub.status.busy": "2023-09-03T08:14:49.842106Z",
     "iopub.status.idle": "2023-09-03T08:14:49.856683Z",
     "shell.execute_reply": "2023-09-03T08:14:49.855262Z",
     "shell.execute_reply.started": "2023-09-03T08:14:49.842585Z"
    }
   },
   "outputs": [],
   "source": [
    "upper_bound_threshold, lower_bound_threshold = 0.8, -0.3\n",
    "# Find features with high correlation scores\n",
    "high_corr_features = np.where(correlation_matrix > upper_bound_threshold)\n",
    "neg_corr_features = np.where(correlation_matrix < lower_bound_threshold)\n",
    "high_corr_features = [(correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "                      for i, j in zip(*high_corr_features) if i != j]\n",
    "neg_corr_features = [(correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "                      for i, j in zip(*neg_corr_features) if i != j]\n",
    "# Convert to a set of unique features\n",
    "high_corr_features = set(feature for pair in high_corr_features for feature in pair)\n",
    "neg_corr_features = set(feature for pair in neg_corr_features for feature in pair)\n",
    "# Remove high correlated features from the dataset\n",
    "data_without_high_corr = data.drop(columns=high_corr_features)\n",
    "# data_without_high_corr = data_without_high_corr.drop(columns=neg_corr_features.difference(high_corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:14:15.125765Z",
     "iopub.status.busy": "2023-09-03T08:14:15.12525Z",
     "iopub.status.idle": "2023-09-03T08:14:27.149985Z",
     "shell.execute_reply": "2023-09-03T08:14:27.148361Z",
     "shell.execute_reply.started": "2023-09-03T08:14:15.125711Z"
    }
   },
   "outputs": [],
   "source": [
    "# # SKIP this cell if do not use object features. Uncomment if use object features\n",
    "# # Visualize the boxplot to find the outlier for all object features\n",
    "# feats_for_find_outlier = (data_without_high_corr.dtypes[data_without_high_corr.dtypes == object]).keys().values.reshape(-1, 2)\n",
    "# num_row, num_col = feats_for_find_outlier.shape[0], feats_for_find_outlier.shape[1]\n",
    "# fig, ax = plt.subplots(num_row, num_col, figsize=(12, 60)) \n",
    "# for row in range(num_row):\n",
    "#     for col in range(num_col):\n",
    "#         sns.boxplot(data=data_without_high_corr, x=feats_for_find_outlier[row,col], y='SalePrice', ax = ax[row,col], dodge=False)\n",
    "# plt.tight_layout() \n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Based on the diagrams above, I select sub-category to remove outliers. Because the number of data rows is not much, I will only select 3 columns (features) to remove outlier: RoofStyle (Gable), BsmtCond (TA), SaleCondition (Abnorml)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:13:15.756661Z",
     "iopub.status.busy": "2023-09-03T08:13:15.756224Z",
     "iopub.status.idle": "2023-09-03T08:13:15.765386Z",
     "shell.execute_reply": "2023-09-03T08:13:15.763956Z",
     "shell.execute_reply.started": "2023-09-03T08:13:15.756628Z"
    }
   },
   "outputs": [],
   "source": [
    "# # SKIP this cell if do not use object features. Uncomment if use object features\n",
    "# col_feats = [\"RoofStyle\", \"BsmtCond\", \"SaleCondition\"]\n",
    "# categorical_of_col = [\"Gable\",\"TA\",\"Abnorml\"]\n",
    "\n",
    "# def find_combination(categorical_of_col, num_items_to_select):\n",
    "#     combinations_of_cat = list(combinations(categorical_of_col, num_items_to_select))\n",
    "#     return combinations_of_cat\n",
    "\n",
    "# def find_outlier_threshold(df_in, target_col, in_col, in_category):\n",
    "#     price_by_cat = df_in[target_col][df_in[in_col]==in_category] \n",
    "#     q1 = price_by_cat.quantile(0.25)\n",
    "#     q3 = price_by_cat.quantile(0.75)\n",
    "#     iqr = q3-q1\n",
    "#     f_low  = q1 - 1.5 * iqr\n",
    "#     f_high = q3 + 1.5 * iqr\n",
    "#     return f_low, f_high \n",
    "\n",
    "# def remove_outlier(df_in, target_col, col_feats, categorical_of_col, fence_low, fence_high):\n",
    "#     remove_ind = []\n",
    "#     for ind in df_in.index:\n",
    "#         if df_in[col_feats][ind] == categorical_of_col:\n",
    "#             if (df_in[target_col][ind] > fence_low) and (df_in[target_col][ind] < fence_high):\n",
    "#                 remove_ind.append(ind)\n",
    "#     for ind in remove_ind:\n",
    "#         df_in = df_in.drop(ind)\n",
    "#     return df_in\n",
    "                \n",
    "# # Find threshold for each feature\n",
    "# fence_low, fence_high = [0]*len(categorical_of_col), [0]*len(categorical_of_col)\n",
    "# for i in range(len(categorical_of_col)):\n",
    "#     fence_low[i], fence_high[i] = find_outlier_threshold(data_without_high_corr, \"SalePrice\", col_feats[i], categorical_of_col[i])\n",
    "# for i in range(len(fence_low)):\n",
    "#     removed_outlier_data = remove_outlier(data_without_high_corr, \"SalePrice\", col_feats[i], categorical_of_col[i], fence_low[i], fence_high[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:13:15.76809Z",
     "iopub.status.busy": "2023-09-03T08:13:15.767548Z",
     "iopub.status.idle": "2023-09-03T08:13:15.784168Z",
     "shell.execute_reply": "2023-09-03T08:13:15.782618Z",
     "shell.execute_reply.started": "2023-09-03T08:13:15.76805Z"
    }
   },
   "outputs": [],
   "source": [
    "# # SKIP this cell if do not use object features.\n",
    "# # For sure test and train have the same dummies\n",
    "# test_set = pd.read_csv('/share/dutta/eyao/dataset/kaggle/house-prices-advanced-regression-techniques/test.csv') \n",
    "# ids = test_set.Id\n",
    "# test_set = preprocess(test_set, train_data=False)\n",
    "# test_set = test_set.drop(columns=high_corr_features)\n",
    "# test_set = test_set.drop(columns=neg_corr_features.difference(high_corr_features))\n",
    "# target = removed_outlier_data.SalePrice \n",
    "# removed_outlier_data = removed_outlier_data.drop(columns=[\"SalePrice\"])\n",
    "\n",
    "# # Create dummies and remove object features\n",
    "# data_type = removed_outlier_data.dtypes\n",
    "# object_features = data_type[data_type==object]\n",
    "# non_object_features = data_type[data_type!=object]\n",
    "# object_data = removed_outlier_data[object_features.keys()]\n",
    "# # Categorical data\n",
    "# len_train = len(removed_outlier_data)\n",
    "# dataset = pd.concat(objs=[removed_outlier_data, test_set], axis=0)\n",
    "# dataset = pd.get_dummies(dataset)\n",
    "# test_set = copy.copy(dataset[len_train:])\n",
    "# source = copy.copy(dataset[:len_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:14:57.004615Z",
     "iopub.status.busy": "2023-09-03T08:14:57.004034Z",
     "iopub.status.idle": "2023-09-03T08:14:57.024249Z",
     "shell.execute_reply": "2023-09-03T08:14:57.022959Z",
     "shell.execute_reply.started": "2023-09-03T08:14:57.00457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to remove outlier without object features\n",
    "def remove_outlier(df_in, col_name):\n",
    "    q1 = df_in[col_name].quantile(0.25) # Q1\n",
    "    q3 = df_in[col_name].quantile(0.75) # Q3\n",
    "    iqr = q3-q1 # Interquartile range\n",
    "    fence_low  = q1-1.5*iqr\n",
    "    fence_high = q3+1.5*iqr\n",
    "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "    return df_out\n",
    "\n",
    "removed_outlier_data = remove_outlier(data_without_high_corr, 'SalePrice') \n",
    "target = removed_outlier_data.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:14:58.638383Z",
     "iopub.status.busy": "2023-09-03T08:14:58.637911Z",
     "iopub.status.idle": "2023-09-03T08:14:58.730214Z",
     "shell.execute_reply": "2023-09-03T08:14:58.728223Z",
     "shell.execute_reply.started": "2023-09-03T08:14:58.638346Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('/share/dutta/eyao/dataset/kaggle/house-prices-advanced-regression-techniques/test.csv') \n",
    "ids = test_set.Id\n",
    "test_set = preprocess_no_obj_feature(test_set, train_data=False)\n",
    "test_set = test_set.drop(columns=high_corr_features)\n",
    "# test_set = test_set.drop(columns=neg_corr_features.difference(high_corr_features))\n",
    "removed_outlier_data = removed_outlier_data.drop(columns=[\"SalePrice\"])\n",
    "source = removed_outlier_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**3. LINEAR REGRESSION MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:15:00.316475Z",
     "iopub.status.busy": "2023-09-03T08:15:00.31588Z",
     "iopub.status.idle": "2023-09-03T08:15:00.774366Z",
     "shell.execute_reply": "2023-09-03T08:15:00.772809Z",
     "shell.execute_reply.started": "2023-09-03T08:15:00.316414Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = source, target\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2) \n",
    "# Initialization\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train) \n",
    "y_pred = LR.predict(X_val) \n",
    "plt.scatter(y_val,y_pred) \n",
    "plt.plot([y_val.min(), y_val.max()], [y_pred.min(), y_pred.max()], 'k--', lw=3)\n",
    "plt.xlabel('y_predicted') \n",
    "plt.ylabel('y_val')\n",
    "plt.title('Linear Regression') \n",
    "plt.show()\n",
    "print(\"Train R2 Score: {}\".format(LR.score(X_train,y_train)))\n",
    "print(\"Test R2 Score: {}\".format(LR.score(X_val,y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:15:02.954136Z",
     "iopub.status.busy": "2023-09-03T08:15:02.953668Z",
     "iopub.status.idle": "2023-09-03T08:15:03.519948Z",
     "shell.execute_reply": "2023-09-03T08:15:03.515236Z",
     "shell.execute_reply.started": "2023-09-03T08:15:02.954098Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_kFolds = cross_val_predict(LR, X.values, y.values, cv = 5)\n",
    "plt.scatter(y, y_pred_kFolds)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_pred_kFolds.min(), y_pred_kFolds.max()], 'k--', lw=3)\n",
    "plt.xlabel('y_Predicted') \n",
    "plt.ylabel('y_Test') \n",
    "plt.title('Linear Regression with K-Folds') \n",
    "plt.show()\n",
    "cv_r2_scores = cross_val_score(LR, source, target, scoring='r2')\n",
    "print(\"Mean 5-Folds R Squared: {}\".format(np.mean(cv_r2_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**4. PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:15:05.594956Z",
     "iopub.status.busy": "2023-09-03T08:15:05.594421Z",
     "iopub.status.idle": "2023-09-03T08:15:05.621063Z",
     "shell.execute_reply": "2023-09-03T08:15:05.618675Z",
     "shell.execute_reply.started": "2023-09-03T08:15:05.594916Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=15)\n",
    "pca_fit = pca.fit_transform(source)\n",
    "pca_df = pd.DataFrame(data = pca_fit, columns = ['pca1','pca2','pca3','pca4','pca5',\n",
    "                                                 'pca6','pca7','pca8','pca9','pca10','pca11',\n",
    "                                                 'pca12','pca13','pca14','pca15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:15:07.182459Z",
     "iopub.status.busy": "2023-09-03T08:15:07.182018Z",
     "iopub.status.idle": "2023-09-03T08:15:07.626522Z",
     "shell.execute_reply": "2023-09-03T08:15:07.624197Z",
     "shell.execute_reply.started": "2023-09-03T08:15:07.182423Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pca_train, X_pca_val, y_train_pca, y_val_pca = train_test_split(pca_df, y, test_size=0.2)\n",
    "LR_pca = LinearRegression()\n",
    "LR_pca.fit(X_pca_train, y_train_pca)\n",
    "y_pred_pca = LR_pca.predict(X_pca_val)\n",
    "plt.scatter(y_val_pca,y_pred_pca) \n",
    "plt.plot([y_val_pca.min(), y_val_pca.max()], [y_pred_pca.min(), y_pred_pca.max()], 'k--', lw=3)\n",
    "plt.xlabel('y_predicted') \n",
    "plt.ylabel('y_val') \n",
    "plt.title('Linear Regression with PCA') \n",
    "plt.show()\n",
    "print(\"Train R2 Score: {}\".format(LR_pca.score(X_pca_train,y_train_pca)))\n",
    "print(\"Test R2 Score: {}\".format(LR_pca.score(X_pca_val,y_val_pca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA does not actually improve the perforrmance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**5. VISUALIZE RESIDUE AND HOMOSCEDASTICITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:15:10.152451Z",
     "iopub.status.busy": "2023-09-03T08:15:10.151971Z",
     "iopub.status.idle": "2023-09-03T08:15:10.517621Z",
     "shell.execute_reply": "2023-09-03T08:15:10.516298Z",
     "shell.execute_reply.started": "2023-09-03T08:15:10.152409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_val - y_pred\n",
    "# Create a residual plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, residuals, color='blue')\n",
    "plt.axhline(y=0, color='red', linestyle='--')  \n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:15:12.73884Z",
     "iopub.status.busy": "2023-09-03T08:15:12.738342Z",
     "iopub.status.idle": "2023-09-03T08:15:13.379805Z",
     "shell.execute_reply": "2023-09-03T08:15:13.378273Z",
     "shell.execute_reply.started": "2023-09-03T08:15:12.738798Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(residuals, bins=200) \n",
    "plt.title('Distribution of Residuals') \n",
    "plt.ylabel('Residuals') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Based on two diagram above, we find:\n",
    "> > 1. Mean of Residual approximately equal to 0. The distribution has the same form as the normal distribution\n",
    "> > 2. Most data points are distributed around the horizontal axis, but there are a few outlier point.\n",
    "> > 3. Linear Regression model is acceptable for prediction of SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**6. TRAINING WITH DIFFERENT METHODS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:15:17.476374Z",
     "iopub.status.busy": "2023-09-03T08:15:17.475953Z",
     "iopub.status.idle": "2023-09-03T08:15:17.485583Z",
     "shell.execute_reply": "2023-09-03T08:15:17.484017Z",
     "shell.execute_reply.started": "2023-09-03T08:15:17.47634Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = source, target \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2023-09-03T08:20:55.069824Z",
     "shell.execute_reply": "2023-09-03T08:20:55.067859Z",
     "shell.execute_reply.started": "2023-09-03T08:15:18.860637Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = [0.01, 0.02, 0.05, 0.1]  \n",
    "subsample = [0.5, 0.2, 0.1] \n",
    "n_estimators = [100, 500, 1000, 1500] \n",
    "max_depth = [None, 3, 6, 9, 12] \n",
    "\n",
    "param_grid = {'learning_rate':learning_rate,\n",
    "              'subsample':subsample,\n",
    "              'n_estimators':n_estimators,\n",
    "              'max_depth':max_depth} \n",
    "\n",
    "GBR = GradientBoostingRegressor() \n",
    "GBR = GridSearchCV(estimator=GBR, param_grid=param_grid, cv=2,n_jobs=-1) \n",
    "GBR.fit(X_train, y_train) \n",
    "print(\"Results from Grid Search\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", GBR.best_estimator_) \n",
    "print(\"\\n The best score across ALL searched params:\\n\", GBR.best_score_) \n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", GBR.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:20:55.07398Z",
     "iopub.status.busy": "2023-09-03T08:20:55.073394Z",
     "iopub.status.idle": "2023-09-03T08:21:01.516492Z",
     "shell.execute_reply": "2023-09-03T08:21:01.514238Z",
     "shell.execute_reply.started": "2023-09-03T08:20:55.073927Z"
    }
   },
   "outputs": [],
   "source": [
    "GBR_best = GradientBoostingRegressor(**GBR.best_params_) # train with best parameter\n",
    "GBR_best.fit(X_train, y_train) \n",
    "y_pred = GBR_best.predict(X_val) \n",
    "print('\\n\\nR-squared val set: ')\n",
    "print(GBR_best.score(X_val, y_val)) \n",
    "print('\\nMAE val set: ')\n",
    "print(mean_absolute_error(y_val, y_pred)) \n",
    "print('\\nMSE val set: ')\n",
    "print(mean_squared_error(y_val, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:25:10.766534Z",
     "iopub.status.busy": "2023-09-03T08:25:10.765971Z",
     "iopub.status.idle": "2023-09-03T08:25:23.851606Z",
     "shell.execute_reply": "2023-09-03T08:25:23.85012Z",
     "shell.execute_reply.started": "2023-09-03T08:25:10.766495Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = [0.01, 0.02, 0.05, 0.1]  \n",
    "loss = ['linear', 'square', 'exponential'] \n",
    "n_estimators = [25, 50, 100, 120] \n",
    "\n",
    "param_grid = {'learning_rate':learning_rate,\n",
    "              'loss': loss,\n",
    "              'n_estimators': n_estimators} \n",
    "\n",
    "ABR = AdaBoostRegressor() \n",
    "ABR = GridSearchCV(estimator=ABR, param_grid=param_grid, cv=2,n_jobs=-1) \n",
    "ABR.fit(X_train, y_train) \n",
    "print(\"Results from Grid Search\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", ABR.best_estimator_) \n",
    "print(\"\\n The best score across ALL searched params:\\n\", ABR.best_score_) \n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", ABR.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:25:23.855461Z",
     "iopub.status.busy": "2023-09-03T08:25:23.854716Z",
     "iopub.status.idle": "2023-09-03T08:25:24.517507Z",
     "shell.execute_reply": "2023-09-03T08:25:24.516139Z",
     "shell.execute_reply.started": "2023-09-03T08:25:23.855405Z"
    }
   },
   "outputs": [],
   "source": [
    "ABR_best = AdaBoostRegressor(**ABR.best_params_) # train with best parameter\n",
    "ABR_best.fit(X_train, y_train) \n",
    "y_pred = ABR_best.predict(X_val) \n",
    "print('\\n\\nR-squared val set: ')\n",
    "print(ABR_best.score(X_val, y_val)) \n",
    "print('\\nMAE val set: ')\n",
    "print(mean_absolute_error(y_val, y_pred)) \n",
    "print('\\nMSE val set: ')\n",
    "print(mean_squared_error(y_val, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:25:24.519989Z",
     "iopub.status.busy": "2023-09-03T08:25:24.519563Z",
     "iopub.status.idle": "2023-09-03T08:25:58.433517Z",
     "shell.execute_reply": "2023-09-03T08:25:58.431495Z",
     "shell.execute_reply.started": "2023-09-03T08:25:24.519956Z"
    }
   },
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 150, 300] \n",
    "max_depth = [None, 4, 6, 8, 10] \n",
    "max_features = ['sqrt', 'log2', None, int, float]\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'max_depth': max_depth,\n",
    "              'max_features': max_features} \n",
    "\n",
    "RFR = RandomForestRegressor() \n",
    "RFR = GridSearchCV(estimator=RFR, param_grid=param_grid, cv=2,n_jobs=-1) \n",
    "RFR.fit(X_train, y_train) \n",
    "print(\"Results from Grid Search\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", RFR.best_estimator_) \n",
    "print(\"\\n The best score across ALL searched params:\\n\", RFR.best_score_) \n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", RFR.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:25:58.438832Z",
     "iopub.status.busy": "2023-09-03T08:25:58.438122Z",
     "iopub.status.idle": "2023-09-03T08:26:01.995839Z",
     "shell.execute_reply": "2023-09-03T08:26:01.993111Z",
     "shell.execute_reply.started": "2023-09-03T08:25:58.438772Z"
    }
   },
   "outputs": [],
   "source": [
    "RFR_best = RandomForestRegressor(**RFR.best_params_) # train with best parameter\n",
    "RFR_best.fit(X_train, y_train) \n",
    "y_pred = RFR_best.predict(X_val) \n",
    "print('\\n\\nR-squared val set: ')\n",
    "print(RFR_best.score(X_val, y_val)) \n",
    "print('\\nMAE val set: ')\n",
    "print(mean_absolute_error(y_val, y_pred)) \n",
    "print('\\nMSE val set: ')\n",
    "print(mean_squared_error(y_val, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:01.998763Z",
     "iopub.status.busy": "2023-09-03T08:26:01.998206Z",
     "iopub.status.idle": "2023-09-03T08:26:26.448412Z",
     "shell.execute_reply": "2023-09-03T08:26:26.44634Z",
     "shell.execute_reply.started": "2023-09-03T08:26:01.998708Z"
    }
   },
   "outputs": [],
   "source": [
    "n_neighbors = [3, 5, 7, 10, 15]   \n",
    "weights = ['uniform', 'distance'] \n",
    "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute'] \n",
    "leaf_size = [20, 30, 50, 70] \n",
    "p = [1, 2, 3]\n",
    "\n",
    "param_grid = {'n_neighbors':n_neighbors,\n",
    "              'weights':weights,\n",
    "              'algorithm':algorithm,\n",
    "              'leaf_size':leaf_size,\n",
    "              'p': p} \n",
    "\n",
    "KNR = KNeighborsRegressor() \n",
    "KNR = GridSearchCV(estimator=KNR, param_grid=param_grid, cv=2,n_jobs=-1) \n",
    "KNR.fit(X_train, y_train) \n",
    "print(\"Results from Grid Search\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", KNR.best_estimator_) \n",
    "print(\"\\n The best score across ALL searched params:\\n\", KNR.best_score_) \n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", KNR.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:26.453539Z",
     "iopub.status.busy": "2023-09-03T08:26:26.451655Z",
     "iopub.status.idle": "2023-09-03T08:26:26.508556Z",
     "shell.execute_reply": "2023-09-03T08:26:26.506661Z",
     "shell.execute_reply.started": "2023-09-03T08:26:26.453468Z"
    }
   },
   "outputs": [],
   "source": [
    "KNR_best = KNeighborsRegressor(**KNR.best_params_) # train with best parameter\n",
    "KNR_best.fit(X_train, y_train) \n",
    "y_pred = KNR_best.predict(X_val) \n",
    "print('\\n\\nR-squared val set: ')\n",
    "print(KNR_best.score(X_val, y_val)) \n",
    "print('\\nMAE val set: ')\n",
    "print(mean_absolute_error(y_val, y_pred)) \n",
    "print('\\nMSE val set: ')\n",
    "print(mean_squared_error(y_val, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:26.513157Z",
     "iopub.status.busy": "2023-09-03T08:26:26.511877Z",
     "iopub.status.idle": "2023-09-03T08:26:32.751779Z",
     "shell.execute_reply": "2023-09-03T08:26:32.749874Z",
     "shell.execute_reply.started": "2023-09-03T08:26:26.513063Z"
    }
   },
   "outputs": [],
   "source": [
    "n_estimators = [5, 10, 20, 25] \n",
    "max_features  = [0.1, 0.2, 0.3, 0.5, 1.0] \n",
    "max_samples = [0.1, 0.2, 0.3, 0.5, 1.0] \n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'max_features': max_features,\n",
    "              'max_samples': max_samples} \n",
    "\n",
    "BR = BaggingRegressor() \n",
    "BR = GridSearchCV(estimator=BR, param_grid=param_grid, cv=2,n_jobs=-1) \n",
    "BR.fit(X_train, y_train) \n",
    "print(\"Results from Grid Search\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", BR.best_estimator_) \n",
    "print(\"\\n The best score across ALL searched params:\\n\", BR.best_score_) \n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", BR.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:32.754531Z",
     "iopub.status.busy": "2023-09-03T08:26:32.754007Z",
     "iopub.status.idle": "2023-09-03T08:26:33.104436Z",
     "shell.execute_reply": "2023-09-03T08:26:33.102361Z",
     "shell.execute_reply.started": "2023-09-03T08:26:32.754489Z"
    }
   },
   "outputs": [],
   "source": [
    "BR_best = BaggingRegressor(**BR.best_params_) # train with best parameter\n",
    "BR_best.fit(X_train, y_train) \n",
    "y_pred = BR_best.predict(X_val) \n",
    "print('\\n\\nR-squared val set: ')\n",
    "print(BR_best.score(X_val, y_val)) \n",
    "print('\\nMAE val set: ')\n",
    "print(mean_absolute_error(y_val, y_pred)) \n",
    "print('\\nMSE val set: ')\n",
    "print(mean_squared_error(y_val, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:33.109038Z",
     "iopub.status.busy": "2023-09-03T08:26:33.10822Z",
     "iopub.status.idle": "2023-09-03T08:26:33.902364Z",
     "shell.execute_reply": "2023-09-03T08:26:33.901309Z",
     "shell.execute_reply.started": "2023-09-03T08:26:33.108982Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'] \n",
    "splitter  = ['best', 'random'] \n",
    "max_depth = [None, 4, 6, 8, 10] \n",
    "\n",
    "param_grid = {'criterion': criterion,\n",
    "              'splitter': splitter,\n",
    "              'max_depth': max_depth} \n",
    "\n",
    "DTR = DecisionTreeRegressor() \n",
    "DTR = GridSearchCV(estimator=DTR, param_grid=param_grid, cv=2,n_jobs=-1) \n",
    "DTR.fit(X_train, y_train) \n",
    "print(\"Results from Grid Search\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", DTR.best_estimator_) \n",
    "print(\"\\n The best score across ALL searched params:\\n\", DTR.best_score_) \n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", DTR.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:33.907994Z",
     "iopub.status.busy": "2023-09-03T08:26:33.907514Z",
     "iopub.status.idle": "2023-09-03T08:26:33.934321Z",
     "shell.execute_reply": "2023-09-03T08:26:33.932832Z",
     "shell.execute_reply.started": "2023-09-03T08:26:33.907957Z"
    }
   },
   "outputs": [],
   "source": [
    "DTR_best = DecisionTreeRegressor(**DTR.best_params_) # train with best parameter\n",
    "DTR_best.fit(X_train, y_train) \n",
    "y_pred = DTR_best.predict(X_val) \n",
    "print('\\n\\nR-squared val set: ')\n",
    "print(DTR_best.score(X_val, y_val)) \n",
    "print('\\nMAE val set: ')\n",
    "print(mean_absolute_error(y_val, y_pred)) \n",
    "print('\\nMSE val set: ')\n",
    "print(mean_squared_error(y_val, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:33.937136Z",
     "iopub.status.busy": "2023-09-03T08:26:33.936681Z",
     "iopub.status.idle": "2023-09-03T08:26:42.134136Z",
     "shell.execute_reply": "2023-09-03T08:26:42.13283Z",
     "shell.execute_reply.started": "2023-09-03T08:26:33.937104Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = [0.01, 0.03, 0.05, 0.07]\n",
    "max_depth = [5, 6, 7]\n",
    "subsample = [0.1, 0.2, 0.5, 0.7]\n",
    "\n",
    "param_grid = {'learning_rate': learning_rate,\n",
    "              'max_depth': max_depth,\n",
    "              'subsample':subsample} \n",
    "\n",
    "XGB = XGBRegressor() \n",
    "XGB = GridSearchCV(estimator=XGB, param_grid=param_grid, cv=2,n_jobs=-1) \n",
    "XGB.fit(X_train, y_train) \n",
    "print(\"Results from Grid Search\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", XGB.best_estimator_) \n",
    "print(\"\\n The best score across ALL searched params:\\n\", XGB.best_score_) \n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", XGB.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:42.142111Z",
     "iopub.status.busy": "2023-09-03T08:26:42.141125Z",
     "iopub.status.idle": "2023-09-03T08:26:42.471662Z",
     "shell.execute_reply": "2023-09-03T08:26:42.470373Z",
     "shell.execute_reply.started": "2023-09-03T08:26:42.142052Z"
    }
   },
   "outputs": [],
   "source": [
    "XGB_best = XGBRegressor(**XGB.best_params_) # train with best parameter\n",
    "XGB_best.fit(X_train, y_train) \n",
    "y_pred = XGB_best.predict(X_val) \n",
    "print('\\n\\nR-squared val set: ')\n",
    "print(DTR_best.score(X_val, y_val)) \n",
    "print('\\nMAE val set: ')\n",
    "print(mean_absolute_error(y_val, y_pred)) \n",
    "print('\\nMSE val set: ')\n",
    "print(mean_squared_error(y_val, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Conclustion:** top 3 models with the highest efficiency based on score of test set.\n",
    "> > Top 1: GradientBoostingRegressor\n",
    "\n",
    "> > Top 2: RandomForestRegressor\n",
    "\n",
    "> > Top 3: BaggingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**7. RETRAIN AND PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:42.478155Z",
     "iopub.status.busy": "2023-09-03T08:26:42.477461Z",
     "iopub.status.idle": "2023-09-03T08:26:42.489587Z",
     "shell.execute_reply": "2023-09-03T08:26:42.488146Z",
     "shell.execute_reply.started": "2023-09-03T08:26:42.478106Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = source, target \n",
    "X_train, y_train = X, y\n",
    "X_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:26:42.493111Z",
     "iopub.status.busy": "2023-09-03T08:26:42.491597Z",
     "iopub.status.idle": "2023-09-03T08:34:07.51807Z",
     "shell.execute_reply": "2023-09-03T08:34:07.516273Z",
     "shell.execute_reply.started": "2023-09-03T08:26:42.493045Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = [0.01, 0.02, 0.05, 0.1]  \n",
    "subsample = [0.5, 0.2, 0.1] \n",
    "n_estimators = [100, 500, 1000, 1500] \n",
    "max_depth = [None, 3, 6, 9, 12] \n",
    "\n",
    "param_grid = {'learning_rate':learning_rate,\n",
    "              'subsample':subsample,\n",
    "              'n_estimators':n_estimators,\n",
    "              'max_depth':max_depth} \n",
    "\n",
    "GBR = GradientBoostingRegressor() \n",
    "GBR = GridSearchCV(estimator=GBR, param_grid=param_grid, cv=2,n_jobs=-1) \n",
    "GBR.fit(X_train, y_train) \n",
    "print(\"Results from Grid Search\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", GBR.best_estimator_) \n",
    "print(\"\\n The best score across ALL searched params:\\n\", GBR.best_score_) \n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", GBR.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_best = GradientBoostingRegressor(**GBR.best_params_) # train with best parameter\n",
    "GBR_best.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:34:07.523374Z",
     "iopub.status.busy": "2023-09-03T08:34:07.522022Z",
     "iopub.status.idle": "2023-09-03T08:34:07.702498Z",
     "shell.execute_reply": "2023-09-03T08:34:07.700503Z",
     "shell.execute_reply.started": "2023-09-03T08:34:07.523325Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = GBR_best.predict(test_set) \n",
    "output = pd.DataFrame({'Id': ids, 'SalePrice': y_pred.squeeze()})\n",
    "output.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:34:07.704874Z",
     "iopub.status.busy": "2023-09-03T08:34:07.704454Z",
     "iopub.status.idle": "2023-09-03T08:34:07.726287Z",
     "shell.execute_reply": "2023-09-03T08:34:07.722864Z",
     "shell.execute_reply.started": "2023-09-03T08:34:07.704842Z"
    }
   },
   "outputs": [],
   "source": [
    "output.to_csv('submission_GBR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:34:07.730181Z",
     "iopub.status.busy": "2023-09-03T08:34:07.729365Z",
     "iopub.status.idle": "2023-09-03T08:34:07.768574Z",
     "shell.execute_reply": "2023-09-03T08:34:07.765168Z",
     "shell.execute_reply.started": "2023-09-03T08:34:07.730121Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_LR = LR.predict(test_set) \n",
    "output_LR = pd.DataFrame({'Id': ids, 'SalePrice': y_pred.squeeze()})\n",
    "output_LR.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-03T08:34:07.775696Z",
     "iopub.status.busy": "2023-09-03T08:34:07.773519Z",
     "iopub.status.idle": "2023-09-03T08:34:07.810474Z",
     "shell.execute_reply": "2023-09-03T08:34:07.807497Z",
     "shell.execute_reply.started": "2023-09-03T08:34:07.775572Z"
    }
   },
   "outputs": [],
   "source": [
    "output_LR.to_csv('submission_LR.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
