{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:33.877723Z",
     "iopub.status.busy": "2023-10-21T13:07:33.87731Z",
     "iopub.status.idle": "2023-10-21T13:07:33.88328Z",
     "shell.execute_reply": "2023-10-21T13:07:33.881939Z",
     "shell.execute_reply.started": "2023-10-21T13:07:33.87769Z"
    }
   },
   "outputs": [],
   "source": [
    "# İş Problemi\n",
    "\n",
    "# Her bir eve ait özelliklerin ve ev fiyatlarının bulunduğu veriseti kullanılarak,\n",
    "# farklı tipteki evlerin fiyatlarına ilişkin bir makine öğrenmesi projesi\n",
    "# gerçekleştirilmek istenmektedir.\n",
    "\n",
    "# Business Problem\n",
    "\n",
    "# Using a dataset of properties and house prices for each house,\n",
    "# a machine learning project on the prices of different types of houses\n",
    "# is intended to be realized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:34.44469Z",
     "iopub.status.busy": "2023-10-21T13:07:34.44417Z",
     "iopub.status.idle": "2023-10-21T13:07:34.451175Z",
     "shell.execute_reply": "2023-10-21T13:07:34.449604Z",
     "shell.execute_reply.started": "2023-10-21T13:07:34.444638Z"
    }
   },
   "outputs": [],
   "source": [
    "# Veri Seti Hikayesi\n",
    "\n",
    "# Ames, Lowa’daki konut evlerinden oluşan bu veri seti içerisinde 79 açıklayıcı değişken bulunduruyor. Kaggle üzerinde bir yarışması \n",
    "# da bulunan projenin veri seti ve yarışma sayfasına aşağıdaki linkten ulaşabilirsiniz. Veri seti bir kaggle yarışmasına ait \n",
    "# olduğundan dolayı train ve test olmak üzere iki farklı csv dosyası vardır. Test veri setinde ev fiyatları boş bırakılmış olup, bu \n",
    "# değerleri sizin tahmin etmeniz beklenmektedir\n",
    "\n",
    "\n",
    "# Dataset Story\n",
    "\n",
    "# This dataset of residential homes in Ames, Iowa contains 79 explanatory variables. A contest on Kaggle \n",
    "# You can access the dataset and the competition page of the project from the link below. The dataset belongs to a kaggle competition \n",
    "# Therefore, there are two different csv files, train and test. In the test dataset, house prices are left blank and this \n",
    "# you are expected to estimate the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:35.947661Z",
     "iopub.status.busy": "2023-10-21T13:07:35.947269Z",
     "iopub.status.idle": "2023-10-21T13:07:35.959043Z",
     "shell.execute_reply": "2023-10-21T13:07:35.957613Z",
     "shell.execute_reply.started": "2023-10-21T13:07:35.947632Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Görev 1: Keşifçi Veri Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:35.973923Z",
     "iopub.status.busy": "2023-10-21T13:07:35.973516Z",
     "iopub.status.idle": "2023-10-21T13:07:36.071601Z",
     "shell.execute_reply": "2023-10-21T13:07:36.070299Z",
     "shell.execute_reply.started": "2023-10-21T13:07:35.973891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 1: Train ve Test veri setlerini okutup birleştiriniz. Birleştirdiğiniz veri üzerinden ilerleyiniz\n",
    "\n",
    "test_df = pd.read_csv(\"/share/dutta/eyao/dataset/kaggle/house-prices-advanced-regression-techniques/test.csv\")\n",
    "train_df = pd.read_csv(\"/share/dutta/eyao/dataset/kaggle/house-prices-advanced-regression-techniques/train.csv\")\n",
    "\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# reset_index() kullanarak indeksi sıfırlayın\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genel Resim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:36.074283Z",
     "iopub.status.busy": "2023-10-21T13:07:36.073835Z",
     "iopub.status.idle": "2023-10-21T13:07:36.08168Z",
     "shell.execute_reply": "2023-10-21T13:07:36.080297Z",
     "shell.execute_reply.started": "2023-10-21T13:07:36.074243Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_df(dataframe, head=5):\n",
    "    print(\"##################### Shape #####################\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"##################### Types #####################\")\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"##################### Head #####################\")\n",
    "    print(dataframe.head(head))\n",
    "    print(\"##################### Tail #####################\")\n",
    "    print(dataframe.tail(head))\n",
    "    print(\"##################### NA #####################\")\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"##################### Quantiles #####################\")\n",
    "    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n",
    "\n",
    "# check_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:36.515331Z",
     "iopub.status.busy": "2023-10-21T13:07:36.514959Z",
     "iopub.status.idle": "2023-10-21T13:07:36.55699Z",
     "shell.execute_reply": "2023-10-21T13:07:36.555778Z",
     "shell.execute_reply.started": "2023-10-21T13:07:36.515302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 2: Numerik ve kategorik değişkenleri yakalayınız\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    \"\"\"\n",
    "    grab_col_names for given dataframe\n",
    "\n",
    "    :param dataframe:\n",
    "    :param cat_th:\n",
    "    :param car_th:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
    "                   dataframe[col].dtypes != \"O\"]\n",
    "\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
    "                   dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "\n",
    "    print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    print(f'cat_cols: {len(cat_cols)}')\n",
    "    print(f'num_cols: {len(num_cols)}')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    print(f'num_but_cat: {len(num_but_cat)}')\n",
    "\n",
    "    # cat_cols + num_cols + cat_but_car = değişken sayısı.\n",
    "    # num_but_cat cat_cols'un içerisinde zaten.\n",
    "    # dolayısıyla tüm şu 3 liste ile tüm değişkenler seçilmiş olacaktır: cat_cols + num_cols + cat_but_car\n",
    "    # num_but_cat sadece raporlama için verilmiştir.\n",
    "\n",
    "    return cat_cols, cat_but_car, num_cols\n",
    "\n",
    "cat_cols, cat_but_car, num_cols = grab_col_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:36.559306Z",
     "iopub.status.busy": "2023-10-21T13:07:36.558868Z",
     "iopub.status.idle": "2023-10-21T13:07:36.565618Z",
     "shell.execute_reply": "2023-10-21T13:07:36.563134Z",
     "shell.execute_reply.started": "2023-10-21T13:07:36.559276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 3: Gerekli düzenlemeleri yapınız. (Tip hatası olan değişkenler gibi)\n",
    "\n",
    "cat_cols += [\"Neighborhood\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kategorik Değişken Analizi (Analysis of Categorical Variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:38.706538Z",
     "iopub.status.busy": "2023-10-21T13:07:38.705516Z",
     "iopub.status.idle": "2023-10-21T13:07:38.88566Z",
     "shell.execute_reply": "2023-10-21T13:07:38.884556Z",
     "shell.execute_reply.started": "2023-10-21T13:07:38.706474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 4: Numerik ve kategorik değişkenlerin veri içindeki dağılımını gözlemleyiniz.\n",
    "\n",
    "def cat_summary(dataframe, col_name, plot=False):\n",
    "    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
    "                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
    "\n",
    "    if plot:\n",
    "        sns.countplot(x=dataframe[col_name], data=dataframe)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for col in cat_cols:\n",
    "    cat_summary(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sayısal Değişken Analizi (Analysis of Numerical Variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:38.888542Z",
     "iopub.status.busy": "2023-10-21T13:07:38.888185Z",
     "iopub.status.idle": "2023-10-21T13:07:52.252179Z",
     "shell.execute_reply": "2023-10-21T13:07:52.25091Z",
     "shell.execute_reply.started": "2023-10-21T13:07:38.888501Z"
    }
   },
   "outputs": [],
   "source": [
    "def num_summary(dataframe, numerical_col, plot=False):\n",
    "    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n",
    "    print(dataframe[numerical_col].describe(quantiles).T)\n",
    "\n",
    "    if plot:\n",
    "        dataframe[numerical_col].hist(bins=50)\n",
    "        plt.xlabel(numerical_col)\n",
    "        plt.title(numerical_col)\n",
    "        plt.show()\n",
    "\n",
    "    print(\"#####################################\")\n",
    "\n",
    "\n",
    "for col in num_cols:\n",
    "    num_summary(df, col, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hedef Değişken Analizi (Analysis of Target Variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:52.254136Z",
     "iopub.status.busy": "2023-10-21T13:07:52.25381Z",
     "iopub.status.idle": "2023-10-21T13:07:52.359075Z",
     "shell.execute_reply": "2023-10-21T13:07:52.357807Z",
     "shell.execute_reply.started": "2023-10-21T13:07:52.254109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 5: Kategorik değişkenler ile hedef değişken incelemesini yapınız.\n",
    "\n",
    "def target_summary_with_cat(dataframe, target, categorical_col):\n",
    "    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "for col in cat_cols:\n",
    "    target_summary_with_cat(df,\"SalePrice\",col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:52.361211Z",
     "iopub.status.busy": "2023-10-21T13:07:52.360831Z",
     "iopub.status.idle": "2023-10-21T13:07:52.872491Z",
     "shell.execute_reply": "2023-10-21T13:07:52.870309Z",
     "shell.execute_reply.started": "2023-10-21T13:07:52.361166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bağımlı değişkenin incelenmesi\n",
    "df[\"SalePrice\"].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:52.87597Z",
     "iopub.status.busy": "2023-10-21T13:07:52.875596Z",
     "iopub.status.idle": "2023-10-21T13:07:53.301226Z",
     "shell.execute_reply": "2023-10-21T13:07:53.30005Z",
     "shell.execute_reply.started": "2023-10-21T13:07:52.87594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bağımlı değişkenin logaritmasının incelenmesi\n",
    "np.log1p(df['SalePrice']).hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korelasyon Analizi (Analysis of Correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:53.303097Z",
     "iopub.status.busy": "2023-10-21T13:07:53.302765Z",
     "iopub.status.idle": "2023-10-21T13:07:54.799456Z",
     "shell.execute_reply": "2023-10-21T13:07:54.798647Z",
     "shell.execute_reply.started": "2023-10-21T13:07:53.303068Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = df[num_cols].corr()\n",
    "corr\n",
    "\n",
    "# Korelasyonların gösterilmesi\n",
    "sns.set(rc={'figure.figsize': (12, 12)})\n",
    "sns.heatmap(corr, cmap=\"RdBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Görev 2: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:54.801699Z",
     "iopub.status.busy": "2023-10-21T13:07:54.801068Z",
     "iopub.status.idle": "2023-10-21T13:07:55.008761Z",
     "shell.execute_reply": "2023-10-21T13:07:55.006977Z",
     "shell.execute_reply.started": "2023-10-21T13:07:54.801664Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 1: Eksik ve aykırı gözlemler için gerekli işlemleri yapınız.\n",
    "\n",
    "\n",
    "# Aykırı değerlerin baskılanması\n",
    "\n",
    "def outlier_thresholds(dataframe, variable, low_quantile=0.10, up_quantile=0.90):\n",
    "    quantile_one = dataframe[variable].quantile(low_quantile)\n",
    "    quantile_three = dataframe[variable].quantile(up_quantile)\n",
    "    interquantile_range = quantile_three - quantile_one\n",
    "    up_limit = quantile_three + 1.5 * interquantile_range\n",
    "    low_limit = quantile_one - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "# Aykırı değer kontrolü\n",
    "def check_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "for col in num_cols:\n",
    "    if col != \"SalePrice\":\n",
    "      print(col, check_outlier(df, col))\n",
    "\n",
    "\n",
    "# Aykırı değerlerin baskılanması\n",
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "\n",
    "\n",
    "for col in num_cols:\n",
    "    if col != \"SalePrice\":\n",
    "        replace_with_thresholds(df,col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksik Değer Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.010737Z",
     "iopub.status.busy": "2023-10-21T13:07:55.010404Z",
     "iopub.status.idle": "2023-10-21T13:07:55.213042Z",
     "shell.execute_reply": "2023-10-21T13:07:55.211371Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.01071Z"
    }
   },
   "outputs": [],
   "source": [
    "def missing_values_table(dataframe, na_name=False):\n",
    "    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n",
    "\n",
    "    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n",
    "\n",
    "    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n",
    "\n",
    "    print(missing_df, end=\"\\n\")\n",
    "\n",
    "    if na_name:\n",
    "        return na_columns\n",
    "\n",
    "missing_values_table(df)\n",
    "\n",
    "\n",
    "df[\"Alley\"].value_counts()\n",
    "df[\"BsmtQual\"].value_counts()\n",
    "\n",
    "\n",
    "# Bazı değişkenlerdeki boş değerler evin o özelliğe sahip olmadığını ifade etmektedir\n",
    "no_cols = [\"Alley\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"FireplaceQu\",\n",
    "           \"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\"PoolQC\",\"Fence\",\"MiscFeature\"]\n",
    "\n",
    "# Kolonlardaki boşlukların \"No\" ifadesi ile doldurulması\n",
    "for col in no_cols:\n",
    "    df[col].fillna(\"No\",inplace=True)\n",
    "\n",
    "missing_values_table(df)\n",
    "\n",
    "\n",
    "\n",
    "# Bu fonsksiyon eksik değerlerin median veya mean ile doldurulmasını sağlar\n",
    "\n",
    "def quick_missing_imp(data, num_method=\"median\", cat_length=20, target=\"SalePrice\"):\n",
    "    variables_with_na = [col for col in data.columns if data[col].isnull().sum() > 0]  # Eksik değere sahip olan değişkenler listelenir\n",
    "\n",
    "    temp_target = data[target]\n",
    "\n",
    "    print(\"# BEFORE\")\n",
    "    print(data[variables_with_na].isnull().sum(), \"\\n\\n\")  # Uygulama öncesi değişkenlerin eksik değerlerinin sayısı\n",
    "\n",
    "    # değişken object ve sınıf sayısı cat_lengthe eşit veya altındaysa boş değerleri mode ile doldur\n",
    "    data = data.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= cat_length) else x, axis=0)\n",
    "\n",
    "    # num_method mean ise tipi object olmayan değişkenlerin boş değerleri ortalama ile dolduruluyor\n",
    "    if num_method == \"mean\":\n",
    "        data = data.apply(lambda x: x.fillna(x.mean()) if x.dtype != \"O\" else x, axis=0)\n",
    "    # num_method median ise tipi object olmayan değişkenlerin boş değerleri ortalama ile dolduruluyor\n",
    "    elif num_method == \"median\":\n",
    "        data = data.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)\n",
    "\n",
    "    data[target] = temp_target\n",
    "\n",
    "    print(\"# AFTER \\n Imputation method is 'MODE' for categorical variables!\")\n",
    "    print(\" Imputation method is '\" + num_method.upper() + \"' for numeric variables! \\n\")\n",
    "    print(data[variables_with_na].isnull().sum(), \"\\n\\n\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "df = quick_missing_imp(df, num_method=\"median\", cat_length=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.215062Z",
     "iopub.status.busy": "2023-10-21T13:07:55.214723Z",
     "iopub.status.idle": "2023-10-21T13:07:55.500149Z",
     "shell.execute_reply": "2023-10-21T13:07:55.498823Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.215035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 2: Rare Encoder uygulayınız.\n",
    "\n",
    "\n",
    "# Kategorik kolonların dağılımının incelenmesi\n",
    "\n",
    "def rare_analyser(dataframe, target, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        print(col, \":\", len(dataframe[col].value_counts()))\n",
    "        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n",
    "                            \"RATIO\": dataframe[col].value_counts() / len(dataframe),\n",
    "                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n",
    "\n",
    "rare_analyser(df, \"SalePrice\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.502827Z",
     "iopub.status.busy": "2023-10-21T13:07:55.502271Z",
     "iopub.status.idle": "2023-10-21T13:07:55.643676Z",
     "shell.execute_reply": "2023-10-21T13:07:55.642555Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.502786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nadir sınıfların tespit edilmesi\n",
    "def rare_encoder(dataframe, rare_perc):\n",
    "    temp_df = dataframe.copy()\n",
    "\n",
    "    rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == 'O'\n",
    "                    and (temp_df[col].value_counts() / len(temp_df) < rare_perc).any(axis=None)]\n",
    "\n",
    "    for var in rare_columns:\n",
    "        tmp = temp_df[var].value_counts() / len(temp_df)\n",
    "        rare_labels = tmp[tmp < rare_perc].index\n",
    "        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "\n",
    "rare_encoder(df,0.01)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.646095Z",
     "iopub.status.busy": "2023-10-21T13:07:55.645395Z",
     "iopub.status.idle": "2023-10-21T13:07:55.675073Z",
     "shell.execute_reply": "2023-10-21T13:07:55.673794Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.646054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 3: Yeni değişkenler oluşturunuz.\n",
    "\n",
    "df[\"NEW_1st*GrLiv\"] = df[\"1stFlrSF\"] * df[\"GrLivArea\"]\n",
    "\n",
    "df[\"NEW_Garage*GrLiv\"] = (df[\"GarageArea\"] * df[\"GrLivArea\"])\n",
    "\n",
    "# df[\"TotalQual\"] = df[[\"OverallQual\", \"OverallCond\", \"ExterQual\", \"ExterCond\", \"BsmtCond\", \"BsmtFinType1\",\n",
    "                     # \"BsmtFinType2\", \"HeatingQC\", \"KitchenQual\", \"Functional\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"Fence\"]].sum(axis = 1) # 42\n",
    "\n",
    "# Total Floor\n",
    "df[\"NEW_TotalFlrSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"] # 32\n",
    "\n",
    "# Total Finished Basement Area\n",
    "df[\"NEW_TotalBsmtFin\"] = df.BsmtFinSF1 + df.BsmtFinSF2 # 56\n",
    "\n",
    "# Porch Area\n",
    "df[\"NEW_PorchArea\"] = df.OpenPorchSF + df.EnclosedPorch + df.ScreenPorch + df[\"3SsnPorch\"] + df.WoodDeckSF # 93\n",
    "\n",
    "# Total House Area\n",
    "df[\"NEW_TotalHouseArea\"] = df.NEW_TotalFlrSF + df.TotalBsmtSF # 156\n",
    "\n",
    "df[\"NEW_TotalSqFeet\"] = df.GrLivArea + df.TotalBsmtSF # 35\n",
    "\n",
    "\n",
    "# Lot Ratio\n",
    "df[\"NEW_LotRatio\"] = df.GrLivArea / df.LotArea # 64\n",
    "\n",
    "df[\"NEW_RatioArea\"] = df.NEW_TotalHouseArea / df.LotArea # 57\n",
    "\n",
    "df[\"NEW_GarageLotRatio\"] = df.GarageArea / df.LotArea # 69\n",
    "\n",
    "# MasVnrArea\n",
    "df[\"NEW_MasVnrRatio\"] = df.MasVnrArea / df.NEW_TotalHouseArea # 36\n",
    "\n",
    "# Dif Area\n",
    "df[\"NEW_DifArea\"] = (df.LotArea - df[\"1stFlrSF\"] - df.GarageArea - df.NEW_PorchArea - df.WoodDeckSF) # 73\n",
    "\n",
    "\n",
    "df[\"NEW_OverallGrade\"] = df[\"OverallQual\"] * df[\"OverallCond\"] # 61\n",
    "\n",
    "\n",
    "df[\"NEW_Restoration\"] = df.YearRemodAdd - df.YearBuilt # 31\n",
    "\n",
    "df[\"NEW_HouseAge\"] = df.YrSold - df.YearBuilt # 73\n",
    "\n",
    "df[\"NEW_RestorationAge\"] = df.YrSold - df.YearRemodAdd # 40\n",
    "\n",
    "df[\"NEW_GarageAge\"] = df.GarageYrBlt - df.YearBuilt # 17\n",
    "\n",
    "df[\"NEW_GarageRestorationAge\"] = np.abs(df.GarageYrBlt - df.YearRemodAdd) # 30\n",
    "\n",
    "df[\"NEW_GarageSold\"] = df.YrSold - df.GarageYrBlt # 48\n",
    "\n",
    "\n",
    "\n",
    "drop_list = [\"Street\", \"Alley\", \"LandContour\", \"Utilities\", \"LandSlope\",\"Heating\", \"PoolQC\", \"MiscFeature\",\"Neighborhood\"]\n",
    "\n",
    "# drop_list'teki değişkenlerin düşürülmesi\n",
    "df.drop(drop_list, axis=1, inplace=True)\n",
    "\n",
    "# df[\"NEW_MSZoning_LotShape\"] = df.MSZoning + \"_\" + df[\"LotShape\"]\n",
    "\n",
    "# df[\"NEW_BldgType_LotConfig\"] = df[\"BldgType\"] + \"_\" + df[\"LotConfig\"]\n",
    "\n",
    "# df[\"NEW_MSZoning_Condition1\"] = df[\"MSZoning\"] + \"_\" + df[\"Condition1\"]\n",
    "\n",
    "# df[\"NEW_MSZoning_Condition2\"] = df[\"MSZoning\"] + \"_\" + df[\"Condition2\"]\n",
    "\n",
    "# df[\"NEW_MSZoning_BldgType\"] = df[\"MSZoning\"] + \"_\" + df.BldgType\n",
    "\n",
    "# df[\"NEW_MSZoning_HouseStyle\"] = df[\"MSZoning\"] + \"_\" + df[\"HouseStyle\"]\n",
    "\n",
    "# df[\"NEW_MSZoning_RoofStyle\"] = df[\"MSZoning\"] + \"_\" + df[\"RoofStyle\"]\n",
    "\n",
    "# df[\"NEW_MSZoning_RoofMatl\"] = df[\"MSZoning\"] + \"_\" + df[\"RoofMatl\"]\n",
    "\n",
    "# df[\"NEW_MasVnrArea/YearBuilt*OverallQual\"] = df[\"MasVnrArea\"] / df[\"YearBuilt\"] * df[\"OverallQual\"]\n",
    "\n",
    "# df[\"NEW_OverallQual*OverallCond-YearBuilt\"] = df[\"OverallQual\"] * df[\"OverallCond\"] - df[\"YearBuilt\"]\n",
    "\n",
    "# df[\"NEW_LotFrontage+LotArea\"] = df[\"LotFrontage\"] + df[\"LotArea\"]\n",
    "\n",
    "# df[\"NEW_TotalBath\"] = df[\"BsmtFullBath\"] + df[\"BsmtHalfBath\"] + df[\"FullBath\"] + df[\"HalfBath\"]\n",
    "\n",
    "# df[\"NEW_Age\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\n",
    "\n",
    "# df[\"NEW_Pool_Garage\"] = df[\"GarageCars\"] + df[\"PoolArea\"]\n",
    "\n",
    "# df[\"NEW_BldgType_HouseStyle\"] = df[\"BldgType\"] + \"_\" + df[\"HouseStyle\"]\n",
    "\n",
    "# df[\"NEW_RoofStyle_RoofMatl\"] = df[\"RoofStyle\"] + \"_\" + df[\"RoofMatl\"]\n",
    "\n",
    "# df[\"NEW_BedroomAbvGr_KitchenAbvGr\"] = df[\"BedroomAbvGr\"] + df[\"KitchenAbvGr\"]\n",
    "\n",
    "# df[\"NEW_GarageType_Finish\"] = df[\"GarageType\"] + \"_\" + df[\"GarageFinish\"]\n",
    "\n",
    "# df[\"NEW_GarageCars_GarageArea_GarageYrBlt\"] = df[\"GarageYrBlt\"] / df[\"GarageCars\"] * df[\"GarageArea\"]\n",
    "\n",
    "# df[\"NEW_BsmtFinType1_BsmtFinType2\"] = df[\"BsmtFinType1\"] + \"_\" + df[\"BsmtFinType2\"]\n",
    "\n",
    "# df[\"NEW_PavedDrive_GarageQual\"] = df[\"GarageQual\"] + \"_\" + df[\"PavedDrive\"]\n",
    "\n",
    "# df[\"NEW_RoofStyle_HouseStyle\"] = df[\"HouseStyle\"] + \"_\" + df[\"RoofStyle\"]\n",
    "\n",
    "# df[\"NEW_Exterior1st_Exterior2nd\"] = df[\"Exterior1st\"] + \"_\" + df[\"Exterior2nd\"]\n",
    "\n",
    "# df[\"NEW_Fence_PavedDrive\"] = df[\"PavedDrive\"] + \"_\" + df[\"Fence\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.677415Z",
     "iopub.status.busy": "2023-10-21T13:07:55.676504Z",
     "iopub.status.idle": "2023-10-21T13:07:55.744295Z",
     "shell.execute_reply": "2023-10-21T13:07:55.742383Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.677381Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding & One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.747138Z",
     "iopub.status.busy": "2023-10-21T13:07:55.746765Z",
     "iopub.status.idle": "2023-10-21T13:07:55.794834Z",
     "shell.execute_reply": "2023-10-21T13:07:55.79375Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.747108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 4: Encoding işlemlerini gerçekleştiriniz.\n",
    "\n",
    "cat_cols, cat_but_car, num_cols = grab_col_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.800288Z",
     "iopub.status.busy": "2023-10-21T13:07:55.799937Z",
     "iopub.status.idle": "2023-10-21T13:07:55.808884Z",
     "shell.execute_reply": "2023-10-21T13:07:55.807677Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.80026Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_encoder(dataframe, binary_col):\n",
    "    labelencoder = LabelEncoder()\n",
    "    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.811563Z",
     "iopub.status.busy": "2023-10-21T13:07:55.810495Z",
     "iopub.status.idle": "2023-10-21T13:07:55.838821Z",
     "shell.execute_reply": "2023-10-21T13:07:55.837111Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.811508Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_cols = [col for col in df.columns if df[col].dtypes == \"O\" and len(df[col].unique()) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.842724Z",
     "iopub.status.busy": "2023-10-21T13:07:55.842308Z",
     "iopub.status.idle": "2023-10-21T13:07:55.850817Z",
     "shell.execute_reply": "2023-10-21T13:07:55.849076Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.842694Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in binary_cols:\n",
    "    label_encoder(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.853401Z",
     "iopub.status.busy": "2023-10-21T13:07:55.853035Z",
     "iopub.status.idle": "2023-10-21T13:07:55.91543Z",
     "shell.execute_reply": "2023-10-21T13:07:55.913904Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.853374Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
    "    return dataframe\n",
    "\n",
    "df = one_hot_encoder(df, cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:55.917457Z",
     "iopub.status.busy": "2023-10-21T13:07:55.917001Z",
     "iopub.status.idle": "2023-10-21T13:07:56.540702Z",
     "shell.execute_reply": "2023-10-21T13:07:56.539566Z",
     "shell.execute_reply.started": "2023-10-21T13:07:55.91742Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    if col != \"SalePrice\":\n",
    "      print(col, check_outlier(df, col))\n",
    "\n",
    "for col in num_cols:\n",
    "    if col != [\"SalePrice\", \"Id\"]:\n",
    "        replace_with_thresholds(df,col)\n",
    "\n",
    "for col in num_cols:\n",
    "    if col != \"SalePrice\":\n",
    "      print(col, check_outlier(df, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:56.542757Z",
     "iopub.status.busy": "2023-10-21T13:07:56.542372Z",
     "iopub.status.idle": "2023-10-21T13:07:56.554395Z",
     "shell.execute_reply": "2023-10-21T13:07:56.553188Z",
     "shell.execute_reply.started": "2023-10-21T13:07:56.54272Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"def minmax_scaler(dataframe, num_cols):\n",
    "    minmaxscaler = MinMaxScaler()\n",
    "    dataframe[num_cols] = minmaxscaler.fit_transform(dataframe[num_cols].values.reshape(-1, 1))\n",
    "    return dataframe\n",
    "\n",
    "num_cols = [col for col in df[num_cols] if col != \"Id\"]\n",
    "\n",
    "for col in num_cols:\n",
    "    minmax_scaler(df, col)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:56.556574Z",
     "iopub.status.busy": "2023-10-21T13:07:56.556195Z",
     "iopub.status.idle": "2023-10-21T13:07:56.564134Z",
     "shell.execute_reply": "2023-10-21T13:07:56.562817Z",
     "shell.execute_reply.started": "2023-10-21T13:07:56.556535Z"
    }
   },
   "outputs": [],
   "source": [
    "# df[\"NEW_MasVnrRatio\"] = df[\"NEW_MasVnrRatio\"].fillna(df[\"NEW_MasVnrRatio\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Görev 3: Model Kurma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:56.566269Z",
     "iopub.status.busy": "2023-10-21T13:07:56.565831Z",
     "iopub.status.idle": "2023-10-21T13:07:56.584953Z",
     "shell.execute_reply": "2023-10-21T13:07:56.583855Z",
     "shell.execute_reply.started": "2023-10-21T13:07:56.566228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 1: Train ve Test verisini ayırınız. (SalePrice değişkeni boş olan değerler test verisidir.\n",
    "train_df = df[df['SalePrice'].notnull()]\n",
    "test_df = df[df['SalePrice'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:56.587403Z",
     "iopub.status.busy": "2023-10-21T13:07:56.586987Z",
     "iopub.status.idle": "2023-10-21T13:07:56.59788Z",
     "shell.execute_reply": "2023-10-21T13:07:56.596788Z",
     "shell.execute_reply.started": "2023-10-21T13:07:56.587364Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train_df['SalePrice'] # np.log1p(df['SalePrice'])\n",
    "X = train_df.drop([\"Id\", \"SalePrice\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:56.60104Z",
     "iopub.status.busy": "2023-10-21T13:07:56.600174Z",
     "iopub.status.idle": "2023-10-21T13:07:57.119453Z",
     "shell.execute_reply": "2023-10-21T13:07:57.118297Z",
     "shell.execute_reply.started": "2023-10-21T13:07:56.600992Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adım 2: Train verisi ile model kurup, model başarısını değerlendiriniz\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=17)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "rmse = np.mean(np.sqrt(-cross_val_score(lr, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:57.129037Z",
     "iopub.status.busy": "2023-10-21T13:07:57.125864Z",
     "iopub.status.idle": "2023-10-21T13:07:57.316362Z",
     "shell.execute_reply": "2023-10-21T13:07:57.31547Z",
     "shell.execute_reply.started": "2023-10-21T13:07:57.128984Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "rmse = np.mean(np.sqrt(-cross_val_score(knn, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:57.321228Z",
     "iopub.status.busy": "2023-10-21T13:07:57.320366Z",
     "iopub.status.idle": "2023-10-21T13:07:57.69848Z",
     "shell.execute_reply": "2023-10-21T13:07:57.697307Z",
     "shell.execute_reply.started": "2023-10-21T13:07:57.321159Z"
    }
   },
   "outputs": [],
   "source": [
    "CART = DecisionTreeRegressor()\n",
    "rmse = np.mean(np.sqrt(-cross_val_score(CART, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:07:57.700543Z",
     "iopub.status.busy": "2023-10-21T13:07:57.700189Z",
     "iopub.status.idle": "2023-10-21T13:08:04.877231Z",
     "shell.execute_reply": "2023-10-21T13:08:04.876098Z",
     "shell.execute_reply.started": "2023-10-21T13:07:57.700499Z"
    }
   },
   "outputs": [],
   "source": [
    "GBM = GradientBoostingRegressor()\n",
    "rmse = np.mean(np.sqrt(-cross_val_score(GBM, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:08:04.879301Z",
     "iopub.status.busy": "2023-10-21T13:08:04.87895Z",
     "iopub.status.idle": "2023-10-21T13:08:10.49385Z",
     "shell.execute_reply": "2023-10-21T13:08:10.492588Z",
     "shell.execute_reply.started": "2023-10-21T13:08:04.879271Z"
    }
   },
   "outputs": [],
   "source": [
    "LightGBM = LGBMRegressor()\n",
    "rmse = np.mean(np.sqrt(-cross_val_score(LightGBM, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:08:10.497782Z",
     "iopub.status.busy": "2023-10-21T13:08:10.497405Z",
     "iopub.status.idle": "2023-10-21T13:08:10.503655Z",
     "shell.execute_reply": "2023-10-21T13:08:10.502861Z",
     "shell.execute_reply.started": "2023-10-21T13:08:10.49775Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMSE: 26139.034 (LR) \n",
    "RMSE: 45084.477 (KNN) \n",
    "RMSE: 37916.060 (CART) \n",
    "RMSE: 25101.333 (GBM) \n",
    "RMSE: 25188.703 (LightGBM) \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:08:10.505772Z",
     "iopub.status.busy": "2023-10-21T13:08:10.50461Z",
     "iopub.status.idle": "2023-10-21T13:08:10.521123Z",
     "shell.execute_reply": "2023-10-21T13:08:10.520042Z",
     "shell.execute_reply.started": "2023-10-21T13:08:10.505741Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"SalePrice\"].mean()\n",
    "# 180450.736\n",
    "df[\"SalePrice\"].std()\n",
    "# 76826.747\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:08:10.522846Z",
     "iopub.status.busy": "2023-10-21T13:08:10.522542Z",
     "iopub.status.idle": "2023-10-21T13:08:11.651473Z",
     "shell.execute_reply": "2023-10-21T13:08:11.650282Z",
     "shell.execute_reply.started": "2023-10-21T13:08:10.522821Z"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# BONUS : Log dönüşümü yaparak model kurunuz ve rmse sonuçlarını gözlemleyiniz.\n",
    "# Not: Log'un tersini (inverse) almayı unutmayınız.\n",
    "##################\n",
    "\n",
    "# Log dönüşümünün gerçekleştirilmesi\n",
    "\n",
    "\n",
    "train_df = df[df[\"SalePrice\"].notnull()]\n",
    "test_df = df[df[\"SalePrice\"].isnull()]\n",
    "\n",
    "y = np.log1p(train_df[\"SalePrice\"])\n",
    "X = train_df.drop([\"Id\", \"SalePrice\"], axis=1)\n",
    "\n",
    "# Verinin eğitim ve tet verisi olarak bölünmesi\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=17)\n",
    "\n",
    "# lgbm_tuned = LGBMRegressor(**lgbm_gs_best.best_params_).fit(X_train, y_train)\n",
    "\n",
    "lgbm = LGBMRegressor().fit(X_train, y_train)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "y_pred\n",
    "# Yapılan LOG dönüşümünün tersinin (inverse'nin) alınması\n",
    "new_y = np.expm1(y_pred)\n",
    "new_y\n",
    "new_y_test = np.expm1(y_test)\n",
    "new_y_test\n",
    "\n",
    "np.sqrt(mean_squared_error(new_y_test, new_y))\n",
    "\n",
    "# RMSE: 25188.703 (LightGBM) \n",
    "# RMSE: 24509.170 (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:08:11.653018Z",
     "iopub.status.busy": "2023-10-21T13:08:11.652709Z",
     "iopub.status.idle": "2023-10-21T13:08:13.071751Z",
     "shell.execute_reply": "2023-10-21T13:08:13.070689Z",
     "shell.execute_reply.started": "2023-10-21T13:08:11.652993Z"
    }
   },
   "outputs": [],
   "source": [
    "gbm = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_test)\n",
    "\n",
    "y_pred\n",
    "# Yapılan LOG dönüşümünün tersinin (inverse'nin) alınması\n",
    "new_y = np.expm1(y_pred)\n",
    "new_y\n",
    "new_y_test = np.expm1(y_test)\n",
    "new_y_test\n",
    "\n",
    "np.sqrt(mean_squared_error(new_y_test, new_y))\n",
    "# RMSE: 25101.333 (GBM) \n",
    "# RMSE: 24947.151 (GBM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:08:13.073447Z",
     "iopub.status.busy": "2023-10-21T13:08:13.073052Z",
     "iopub.status.idle": "2023-10-21T13:10:15.561019Z",
     "shell.execute_reply": "2023-10-21T13:10:15.559917Z",
     "shell.execute_reply.started": "2023-10-21T13:08:13.07342Z"
    }
   },
   "outputs": [],
   "source": [
    "# hiperparametre optimizasyonlarını gerçekleştiriniz.\n",
    "\n",
    "lgbm_model = LGBMRegressor(random_state=46)\n",
    "\n",
    "rmse = np.mean(np.sqrt(-cross_val_score(lgbm_model, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n",
    "print(rmse)\n",
    "\n",
    "lgbm_params = {\"learning_rate\": [0.01, 0.1],\n",
    "              \"n_estimators\": [500, 1500]\n",
    "              #\"colsample_bytree\": [0.5, 0.7, 1]\n",
    "              }\n",
    "\n",
    "lgbm_gs_best = GridSearchCV(lgbm_model,\n",
    "                           lgbm_params,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:10:15.56273Z",
     "iopub.status.busy": "2023-10-21T13:10:15.562374Z",
     "iopub.status.idle": "2023-10-21T13:11:35.812697Z",
     "shell.execute_reply": "2023-10-21T13:11:35.81154Z",
     "shell.execute_reply.started": "2023-10-21T13:10:15.562704Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model = lgbm_model.set_params(**lgbm_gs_best.best_params_).fit(X, y)\n",
    "\n",
    "rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:11:35.814501Z",
     "iopub.status.busy": "2023-10-21T13:11:35.814079Z",
     "iopub.status.idle": "2023-10-21T13:11:41.563625Z",
     "shell.execute_reply": "2023-10-21T13:11:41.562594Z",
     "shell.execute_reply.started": "2023-10-21T13:11:35.814462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Değişkenlerin önem düzeyini belirten feature_importance fonksiyonunu kullanarak özelliklerin sıralamasını çizdiriniz.\n",
    "\n",
    "# feature importance\n",
    "def plot_importance(model, features, num=len(X), save=False):\n",
    "\n",
    "    feature_imp = pd.DataFrame({\"Value\": model.feature_importances_, \"Feature\": features.columns})\n",
    "    plt.figure(figsize=(40, 40))\n",
    "    sns.set(font_scale=1)  # Yazı boyutunu düşürdük\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[0:num])\n",
    "    plt.title(\"Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig(\"importances.png\")\n",
    "\n",
    "model = LGBMRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "plot_importance(model, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Id'] = test_df['Id'].astype(int)\n",
    "test_df['Id'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:16:28.739429Z",
     "iopub.status.busy": "2023-10-21T13:16:28.739035Z",
     "iopub.status.idle": "2023-10-21T13:16:30.740757Z",
     "shell.execute_reply": "2023-10-21T13:16:30.739576Z",
     "shell.execute_reply.started": "2023-10-21T13:16:28.739396Z"
    }
   },
   "outputs": [],
   "source": [
    "# test dataframeindeki boş olan salePrice değişkenlerini tahminleyiniz ve\n",
    "# Kaggle sayfasına submit etmeye uygun halde bir dataframe oluşturunuz. (Id, SalePrice)\n",
    "\n",
    "model = LGBMRegressor()\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(test_df.drop([\"Id\", \"SalePrice\"], axis=1))\n",
    "\n",
    "dictionary = {\"Id\": test_df['Id'], \"SalePrice\": predictions}\n",
    "dfSubmission = pd.DataFrame(dictionary)\n",
    "dfSubmission.to_csv(\"housePricePredictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T13:11:42.65333Z",
     "iopub.status.busy": "2023-10-21T13:11:42.652793Z",
     "iopub.status.idle": "2023-10-21T13:11:42.795462Z",
     "shell.execute_reply": "2023-10-21T13:11:42.794338Z",
     "shell.execute_reply.started": "2023-10-21T13:11:42.653299Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
